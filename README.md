# deep_inference_cpu
Examples and demo codes for optimizing deep learning models for extremely fast inference

## optimizing inference on CPU devices powered by Intel's distribution of OpenVino

Steps to run the code: 
1. Install OpenVino
2. Activate the virtual environment
3. Add the environmen to local jupyer notebook
4. Change the kernel from jupyter menu
5. Run the code in the jupyer and test with you own images.

**important** : make sure model files and data files are present in the target directories.

Reference:
https://github.com/openvinotoolkit/openvino_notebooks
